from pyspark.sql import SparkSession

# Initialize Spark session
spark = SparkSession.builder \
    .appName("Read from BigQuery") \
    .config("spark.jars", "gs://spark-lib/bigquery/spark-bigquery-latest_2.12.jar") \
    .getOrCreate()

# Set up the BigQuery connector .. This is optional
spark.conf.set("spark.sql.extensions", "com.google.cloud.spark.bigquery.BigQueryRelationProvider")

# Define BigQuery table to read
table_name = "your_project.your_dataset.your_table"  # Replace with your project ID, dataset, and table name

# Read data from BigQuery into a DataFrame
df = spark.read.format("bigquery") \
    .option("table", table_name) \
    .load()

# Show the first few rows of the DataFrame
df.show()

# Stop Spark session
spark.stop()

================================================================================================================================================================

## If The spark-bigquery connector is included in the Spark distribution used on Google Cloud Dataproc and other managed Spark environments by default. Then no need to connect bq connector using spark.conf.set

from pyspark.sql import SparkSession
# Initialize Spark session
spark = SparkSession.builder \
    .appName("Read from BigQuery") \
    .getOrCreate()

# Define BigQuery table to read
table_name = "your_project.your_dataset.your_table"  # Replace with your project ID, dataset, and table name

# Read data from BigQuery into a DataFrame
df = spark.read.format("bigquery") \
    .option("table", table_name) \
    .load()

# Show the first few rows of the DataFrame
df.show()

# Stop Spark session
spark.stop()

